{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba \n",
    "import jieba.analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>﻿怎么更改花呗手机号码</td>\n",
       "      <td>我的花呗是以前的手机号码，怎么更改成现在的支付宝的号码手机号</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>也开不了花呗，就这样了？完事了</td>\n",
       "      <td>真的嘛？就是花呗付款</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>花呗冻结以后还能开通吗</td>\n",
       "      <td>我的条件可以开通花呗借款吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>如何得知关闭借呗</td>\n",
       "      <td>想永久关闭借呗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>花呗扫码付钱</td>\n",
       "      <td>二维码扫描可以用花呗吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id            text1                           text2  label\n",
       "0           0   1      ﻿怎么更改花呗手机号码  我的花呗是以前的手机号码，怎么更改成现在的支付宝的号码手机号      1\n",
       "1           1   2  也开不了花呗，就这样了？完事了                      真的嘛？就是花呗付款      0\n",
       "2           2   3      花呗冻结以后还能开通吗                   我的条件可以开通花呗借款吗      0\n",
       "3           3   4         如何得知关闭借呗                         想永久关闭借呗      0\n",
       "4           4   5           花呗扫码付钱                     二维码扫描可以用花呗吗      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text1 = list(data['text1'])\n",
    "text2 = list(data['text2'])\n",
    "labels = list(data['label'])\n",
    "assert len(text1) == len(text2)\n",
    "texts = text1 + text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for text in texts:\n",
    "    for sentence in re.findall(r'\\w+', text):\n",
    "        for i in range(len(sentence)-1):\n",
    "            word = sentence[i:i+2]\n",
    "            tokens.append(word)\n",
    "counter_2 = Counter(tokens)\n",
    "most_common_2 = [word[0] for word in counter_2.most_common(30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens_3 = []\n",
    "texts = data['text1']\n",
    "for text in texts:\n",
    "    for sentence in re.findall(r'\\w+', text):\n",
    "        for i in range(len(sentence)-2):\n",
    "            word = sentence[i:i+3]\n",
    "            tokens_3.append(word)\n",
    "            \n",
    "counter_3 = Counter(tokens_3)\n",
    "most_common_3 = [word[0] for word in counter_3.most_common(30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['花呗',\n",
       " '借呗',\n",
       " '怎么',\n",
       " '什么',\n",
       " '还款',\n",
       " '可以',\n",
       " '蚂蚁',\n",
       " '为什',\n",
       " '额度',\n",
       " '我的',\n",
       " '蚁借',\n",
       " '分期',\n",
       " '开通',\n",
       " '用花',\n",
       " '支付',\n",
       " '的花',\n",
       " '呗还',\n",
       " '不能',\n",
       " '没有',\n",
       " '使用',\n",
       " '呗分',\n",
       " '付款',\n",
       " '呗的',\n",
       " '不了',\n",
       " '付宝',\n",
       " '个月',\n",
       " '呗怎',\n",
       " '蚁花',\n",
       " '么我',\n",
       " '呗额']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'花呗'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = most_common_2[0]\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords = most_common_2 + most_common_3\n",
    "word_vector = np.zeros((len(text1), 2*len(keywords)))\n",
    "for i, word in enumerate(keywords):\n",
    "    ip = i + len(keywords)\n",
    "    for j in range(len(word_vector)):\n",
    "        if word in text1[j]:\n",
    "            word_vector[j, i] = 1\n",
    "        if word in text2[j]:\n",
    "            word_vector[j, ip] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key word extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_key_word(sentence,topK):\n",
    "    return jieba.analyse.extract_tags(sentence,topK = topK)\n",
    "def get_all_key_word(sentences,topK):\n",
    "    res = []\n",
    "    for i in range(len(sentences)):\n",
    "        key_word = get_key_word(sentences[i],topK)\n",
    "        res.extend(key_word)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.991 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# add dictionary words\n",
    "added_words = ['花呗','借呗','怎么','什么','我的']\n",
    "for i in added_words:\n",
    "    jieba.add_word(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter_key = Counter(get_all_key_word(text1,5)+get_all_key_word(text2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_common_key = [word[0] for word in counter_key.most_common(120)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_key = [word for word in counter_key] #7000+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### get training data\n",
    "\n",
    "word_vector = np.zeros((len(text1), 2*len(most_common_key)))\n",
    "for i, word in enumerate(most_common_key):\n",
    "    ip = i + len(most_common_key)\n",
    "    for j in range(len(word_vector)):\n",
    "        if word in text1[j]:\n",
    "            word_vector[j, i] = 1\n",
    "        if word in text2[j]:\n",
    "            word_vector[j, ip] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = word_vector.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_ = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "39312/39312 [==============================] - 6s 163us/step - loss: 0.5196 - acc: 0.7824\n",
      "Epoch 2/150\n",
      "39312/39312 [==============================] - 5s 121us/step - loss: 0.5097 - acc: 0.7826\n",
      "Epoch 3/150\n",
      "39312/39312 [==============================] - 5s 117us/step - loss: 0.5027 - acc: 0.7840\n",
      "Epoch 4/150\n",
      "39312/39312 [==============================] - 5s 120us/step - loss: 0.4948 - acc: 0.7843\n",
      "Epoch 5/150\n",
      "39312/39312 [==============================] - 5s 120us/step - loss: 0.4894 - acc: 0.7854\n",
      "Epoch 6/150\n",
      "39312/39312 [==============================] - 5s 134us/step - loss: 0.4849 - acc: 0.7855\n",
      "Epoch 7/150\n",
      "39312/39312 [==============================] - 5s 128us/step - loss: 0.4809 - acc: 0.7865\n",
      "Epoch 8/150\n",
      "39312/39312 [==============================] - 5s 126us/step - loss: 0.4767 - acc: 0.7879\n",
      "Epoch 9/150\n",
      "39312/39312 [==============================] - 5s 121us/step - loss: 0.4727 - acc: 0.7879\n",
      "Epoch 10/150\n",
      "39312/39312 [==============================] - 5s 120us/step - loss: 0.4689 - acc: 0.7899\n",
      "Epoch 11/150\n",
      "39312/39312 [==============================] - 5s 118us/step - loss: 0.4657 - acc: 0.7908\n",
      "Epoch 12/150\n",
      "39312/39312 [==============================] - 5s 123us/step - loss: 0.4620 - acc: 0.7918\n",
      "Epoch 13/150\n",
      "39312/39312 [==============================] - 5s 117us/step - loss: 0.4588 - acc: 0.7935\n",
      "Epoch 14/150\n",
      "39312/39312 [==============================] - 5s 126us/step - loss: 0.4559 - acc: 0.7954\n",
      "Epoch 15/150\n",
      "39312/39312 [==============================] - 5s 115us/step - loss: 0.4528 - acc: 0.7953\n",
      "Epoch 16/150\n",
      "39312/39312 [==============================] - 5s 118us/step - loss: 0.4495 - acc: 0.7973\n",
      "Epoch 17/150\n",
      "39312/39312 [==============================] - 6s 154us/step - loss: 0.4464 - acc: 0.7980\n",
      "Epoch 18/150\n",
      "39312/39312 [==============================] - 5s 130us/step - loss: 0.4438 - acc: 0.7996\n",
      "Epoch 19/150\n",
      "39312/39312 [==============================] - 5s 139us/step - loss: 0.4405 - acc: 0.8010\n",
      "Epoch 20/150\n",
      "39312/39312 [==============================] - 5s 134us/step - loss: 0.4385 - acc: 0.8006\n",
      "Epoch 21/150\n",
      "39312/39312 [==============================] - 6s 145us/step - loss: 0.4359 - acc: 0.8032\n",
      "Epoch 22/150\n",
      "39312/39312 [==============================] - 5s 137us/step - loss: 0.4338 - acc: 0.8033\n",
      "Epoch 23/150\n",
      "39312/39312 [==============================] - 5s 138us/step - loss: 0.4309 - acc: 0.8049\n",
      "Epoch 24/150\n",
      "39312/39312 [==============================] - 6s 141us/step - loss: 0.4284 - acc: 0.8063\n",
      "Epoch 25/150\n",
      "39312/39312 [==============================] - 5s 133us/step - loss: 0.4254 - acc: 0.8071\n",
      "Epoch 26/150\n",
      "39312/39312 [==============================] - 5s 127us/step - loss: 0.4248 - acc: 0.8068\n",
      "Epoch 27/150\n",
      "39312/39312 [==============================] - 5s 122us/step - loss: 0.4209 - acc: 0.8087\n",
      "Epoch 28/150\n",
      "39312/39312 [==============================] - 5s 126us/step - loss: 0.4197 - acc: 0.8091\n",
      "Epoch 29/150\n",
      "39312/39312 [==============================] - 5s 124us/step - loss: 0.4172 - acc: 0.8108\n",
      "Epoch 30/150\n",
      "39312/39312 [==============================] - 5s 121us/step - loss: 0.4156 - acc: 0.8117\n",
      "Epoch 31/150\n",
      "39312/39312 [==============================] - 5s 133us/step - loss: 0.4134 - acc: 0.8131\n",
      "Epoch 32/150\n",
      "39312/39312 [==============================] - 5s 115us/step - loss: 0.4116 - acc: 0.8139\n",
      "Epoch 33/150\n",
      "39312/39312 [==============================] - 5s 117us/step - loss: 0.4090 - acc: 0.8156\n",
      "Epoch 34/150\n",
      "39312/39312 [==============================] - 5s 118us/step - loss: 0.4080 - acc: 0.8157\n",
      "Epoch 35/150\n",
      "39312/39312 [==============================] - 5s 132us/step - loss: 0.4059 - acc: 0.8153\n",
      "Epoch 36/150\n",
      "39312/39312 [==============================] - 6s 141us/step - loss: 0.4044 - acc: 0.8171\n",
      "Epoch 37/150\n",
      "39312/39312 [==============================] - 5s 121us/step - loss: 0.4026 - acc: 0.8176\n",
      "Epoch 38/150\n",
      "39312/39312 [==============================] - 5s 126us/step - loss: 0.4011 - acc: 0.8181\n",
      "Epoch 39/150\n",
      "39312/39312 [==============================] - 6s 157us/step - loss: 0.3995 - acc: 0.8189\n",
      "Epoch 40/150\n",
      "39312/39312 [==============================] - 5s 136us/step - loss: 0.3973 - acc: 0.8204\n",
      "Epoch 41/150\n",
      "39312/39312 [==============================] - 5s 137us/step - loss: 0.3968 - acc: 0.8200\n",
      "Epoch 42/150\n",
      "39312/39312 [==============================] - 5s 135us/step - loss: 0.3951 - acc: 0.8199\n",
      "Epoch 43/150\n",
      "39312/39312 [==============================] - 5s 126us/step - loss: 0.3942 - acc: 0.8212\n",
      "Epoch 44/150\n",
      "39312/39312 [==============================] - 5s 128us/step - loss: 0.3912 - acc: 0.8232\n",
      "Epoch 45/150\n",
      "39312/39312 [==============================] - 5s 131us/step - loss: 0.3906 - acc: 0.8246\n",
      "Epoch 46/150\n",
      "39312/39312 [==============================] - 5s 121us/step - loss: 0.3895 - acc: 0.8245\n",
      "Epoch 47/150\n",
      "39312/39312 [==============================] - 6s 141us/step - loss: 0.3882 - acc: 0.8243\n",
      "Epoch 48/150\n",
      "39312/39312 [==============================] - 5s 122us/step - loss: 0.3871 - acc: 0.8262\n",
      "Epoch 49/150\n",
      "39312/39312 [==============================] - 5s 132us/step - loss: 0.3862 - acc: 0.8244\n",
      "Epoch 50/150\n",
      "39312/39312 [==============================] - 5s 124us/step - loss: 0.3850 - acc: 0.8260\n",
      "Epoch 51/150\n",
      "39312/39312 [==============================] - 6s 150us/step - loss: 0.3838 - acc: 0.8269\n",
      "Epoch 52/150\n",
      "39312/39312 [==============================] - 5s 129us/step - loss: 0.3825 - acc: 0.8266\n",
      "Epoch 53/150\n",
      "39312/39312 [==============================] - 6s 142us/step - loss: 0.3817 - acc: 0.8274\n",
      "Epoch 54/150\n",
      "39312/39312 [==============================] - 6s 146us/step - loss: 0.3812 - acc: 0.8282\n",
      "Epoch 55/150\n",
      "39312/39312 [==============================] - 6s 145us/step - loss: 0.3802 - acc: 0.8285\n",
      "Epoch 56/150\n",
      "39312/39312 [==============================] - 5s 129us/step - loss: 0.3783 - acc: 0.8283\n",
      "Epoch 57/150\n",
      "39312/39312 [==============================] - 7s 166us/step - loss: 0.3773 - acc: 0.8302\n",
      "Epoch 58/150\n",
      "39312/39312 [==============================] - 7s 165us/step - loss: 0.3766 - acc: 0.8298\n",
      "Epoch 59/150\n",
      "39312/39312 [==============================] - 6s 146us/step - loss: 0.3767 - acc: 0.8299\n",
      "Epoch 60/150\n",
      "39312/39312 [==============================] - 5s 131us/step - loss: 0.3749 - acc: 0.8313\n",
      "Epoch 61/150\n",
      "39312/39312 [==============================] - 6s 142us/step - loss: 0.3745 - acc: 0.8312\n",
      "Epoch 62/150\n",
      "39312/39312 [==============================] - 6s 141us/step - loss: 0.3736 - acc: 0.8325\n",
      "Epoch 63/150\n",
      "39312/39312 [==============================] - 6s 159us/step - loss: 0.3730 - acc: 0.8310\n",
      "Epoch 64/150\n",
      "39312/39312 [==============================] - 6s 164us/step - loss: 0.3727 - acc: 0.8340\n",
      "Epoch 65/150\n",
      "39312/39312 [==============================] - 6s 142us/step - loss: 0.3716 - acc: 0.8323\n",
      "Epoch 66/150\n",
      "39312/39312 [==============================] - 6s 155us/step - loss: 0.3693 - acc: 0.8339\n",
      "Epoch 67/150\n",
      "39312/39312 [==============================] - 5s 137us/step - loss: 0.3693 - acc: 0.8337\n",
      "Epoch 68/150\n",
      "39312/39312 [==============================] - 6s 155us/step - loss: 0.3684 - acc: 0.8337\n",
      "Epoch 69/150\n",
      "39312/39312 [==============================] - 6s 161us/step - loss: 0.3689 - acc: 0.8354\n",
      "Epoch 70/150\n",
      "39312/39312 [==============================] - 6s 145us/step - loss: 0.3652 - acc: 0.8355\n",
      "Epoch 71/150\n",
      "39312/39312 [==============================] - 5s 132us/step - loss: 0.3663 - acc: 0.8348\n",
      "Epoch 72/150\n",
      "39312/39312 [==============================] - 5s 121us/step - loss: 0.3649 - acc: 0.8361\n",
      "Epoch 73/150\n",
      "39312/39312 [==============================] - 5s 120us/step - loss: 0.3647 - acc: 0.8367\n",
      "Epoch 74/150\n",
      "39312/39312 [==============================] - 5s 123us/step - loss: 0.3639 - acc: 0.8371\n",
      "Epoch 75/150\n",
      "39312/39312 [==============================] - 5s 121us/step - loss: 0.3627 - acc: 0.8371\n",
      "Epoch 76/150\n",
      "39312/39312 [==============================] - 5s 128us/step - loss: 0.3628 - acc: 0.8366\n",
      "Epoch 77/150\n",
      "39312/39312 [==============================] - 5s 124us/step - loss: 0.3615 - acc: 0.8368\n",
      "Epoch 78/150\n",
      "39312/39312 [==============================] - 5s 126us/step - loss: 0.3614 - acc: 0.8377\n",
      "Epoch 79/150\n",
      "39312/39312 [==============================] - 5s 121us/step - loss: 0.3609 - acc: 0.8374\n",
      "Epoch 80/150\n",
      "39312/39312 [==============================] - 5s 122us/step - loss: 0.3598 - acc: 0.8384\n",
      "Epoch 81/150\n",
      "39312/39312 [==============================] - 5s 122us/step - loss: 0.3591 - acc: 0.8372\n",
      "Epoch 82/150\n",
      "39312/39312 [==============================] - 5s 120us/step - loss: 0.3585 - acc: 0.8384\n",
      "Epoch 83/150\n",
      "39312/39312 [==============================] - 5s 121us/step - loss: 0.3586 - acc: 0.8390\n",
      "Epoch 84/150\n",
      "39312/39312 [==============================] - 5s 121us/step - loss: 0.3565 - acc: 0.8398\n",
      "Epoch 85/150\n",
      "39312/39312 [==============================] - 5s 121us/step - loss: 0.3571 - acc: 0.8400\n",
      "Epoch 86/150\n",
      "39312/39312 [==============================] - 5s 122us/step - loss: 0.3565 - acc: 0.8402\n",
      "Epoch 87/150\n",
      "39312/39312 [==============================] - 5s 122us/step - loss: 0.3555 - acc: 0.8409\n",
      "Epoch 88/150\n",
      "39312/39312 [==============================] - 5s 120us/step - loss: 0.3557 - acc: 0.8403\n",
      "Epoch 89/150\n",
      "39312/39312 [==============================] - 5s 119us/step - loss: 0.3541 - acc: 0.8409\n",
      "Epoch 90/150\n",
      "39312/39312 [==============================] - 5s 123us/step - loss: 0.3540 - acc: 0.8421\n",
      "Epoch 91/150\n",
      "39312/39312 [==============================] - 5s 120us/step - loss: 0.3538 - acc: 0.8415\n",
      "Epoch 92/150\n",
      "39312/39312 [==============================] - 6s 141us/step - loss: 0.3545 - acc: 0.8401\n",
      "Epoch 93/150\n",
      "39312/39312 [==============================] - 5s 134us/step - loss: 0.3534 - acc: 0.8403\n",
      "Epoch 94/150\n",
      "39312/39312 [==============================] - 6s 147us/step - loss: 0.3517 - acc: 0.8419\n",
      "Epoch 95/150\n",
      "39312/39312 [==============================] - 6s 148us/step - loss: 0.3518 - acc: 0.8427\n",
      "Epoch 96/150\n",
      "39312/39312 [==============================] - 6s 148us/step - loss: 0.3511 - acc: 0.8427\n",
      "Epoch 97/150\n",
      "39312/39312 [==============================] - 6s 143us/step - loss: 0.3506 - acc: 0.8424\n",
      "Epoch 98/150\n",
      "39312/39312 [==============================] - 5s 139us/step - loss: 0.3505 - acc: 0.8425\n",
      "Epoch 99/150\n",
      "39312/39312 [==============================] - 7s 172us/step - loss: 0.3489 - acc: 0.8425\n",
      "Epoch 100/150\n",
      "39312/39312 [==============================] - 8s 200us/step - loss: 0.3501 - acc: 0.8436\n",
      "Epoch 101/150\n",
      "39312/39312 [==============================] - 8s 197us/step - loss: 0.3488 - acc: 0.8433\n",
      "Epoch 102/150\n",
      "39312/39312 [==============================] - 7s 190us/step - loss: 0.3482 - acc: 0.8432\n",
      "Epoch 103/150\n",
      "39312/39312 [==============================] - 6s 160us/step - loss: 0.3486 - acc: 0.8441\n",
      "Epoch 104/150\n",
      "39312/39312 [==============================] - 7s 170us/step - loss: 0.3490 - acc: 0.8438\n",
      "Epoch 105/150\n",
      "39312/39312 [==============================] - 6s 161us/step - loss: 0.3469 - acc: 0.8440\n",
      "Epoch 106/150\n",
      "39312/39312 [==============================] - 7s 177us/step - loss: 0.3464 - acc: 0.8447\n",
      "Epoch 107/150\n",
      "39312/39312 [==============================] - 6s 147us/step - loss: 0.3462 - acc: 0.8445\n",
      "Epoch 108/150\n",
      "39312/39312 [==============================] - 6s 160us/step - loss: 0.3455 - acc: 0.8454\n",
      "Epoch 109/150\n",
      "39312/39312 [==============================] - 6s 160us/step - loss: 0.3461 - acc: 0.8431\n",
      "Epoch 110/150\n",
      "39312/39312 [==============================] - 6s 146us/step - loss: 0.3456 - acc: 0.8443\n",
      "Epoch 111/150\n",
      "39312/39312 [==============================] - 6s 154us/step - loss: 0.3446 - acc: 0.8458\n",
      "Epoch 112/150\n",
      "39312/39312 [==============================] - 7s 173us/step - loss: 0.3442 - acc: 0.8452\n",
      "Epoch 113/150\n",
      "39312/39312 [==============================] - 7s 173us/step - loss: 0.3428 - acc: 0.8470\n",
      "Epoch 114/150\n",
      "39312/39312 [==============================] - 7s 184us/step - loss: 0.3440 - acc: 0.8447\n",
      "Epoch 115/150\n",
      "39312/39312 [==============================] - 6s 145us/step - loss: 0.3429 - acc: 0.8460\n",
      "Epoch 116/150\n",
      "39312/39312 [==============================] - 6s 145us/step - loss: 0.3437 - acc: 0.8468\n",
      "Epoch 117/150\n",
      "39312/39312 [==============================] - 6s 145us/step - loss: 0.3413 - acc: 0.8469\n",
      "Epoch 118/150\n",
      "39312/39312 [==============================] - 5s 137us/step - loss: 0.3421 - acc: 0.8464\n",
      "Epoch 119/150\n",
      "39312/39312 [==============================] - 5s 137us/step - loss: 0.3421 - acc: 0.8457\n",
      "Epoch 120/150\n",
      "39312/39312 [==============================] - 5s 136us/step - loss: 0.3405 - acc: 0.8473\n",
      "Epoch 121/150\n",
      "39312/39312 [==============================] - 6s 143us/step - loss: 0.3406 - acc: 0.8465\n",
      "Epoch 122/150\n",
      "39312/39312 [==============================] - 6s 153us/step - loss: 0.3415 - acc: 0.8467\n",
      "Epoch 123/150\n",
      "39312/39312 [==============================] - 6s 146us/step - loss: 0.3408 - acc: 0.8474\n",
      "Epoch 124/150\n",
      "39312/39312 [==============================] - 5s 123us/step - loss: 0.3395 - acc: 0.8477\n",
      "Epoch 125/150\n",
      "39312/39312 [==============================] - 5s 128us/step - loss: 0.3390 - acc: 0.8481\n",
      "Epoch 126/150\n",
      "39312/39312 [==============================] - 5s 120us/step - loss: 0.3394 - acc: 0.8466\n",
      "Epoch 127/150\n",
      "39312/39312 [==============================] - 5s 124us/step - loss: 0.3387 - acc: 0.8488\n",
      "Epoch 128/150\n",
      "39312/39312 [==============================] - 5s 116us/step - loss: 0.3388 - acc: 0.8488\n",
      "Epoch 129/150\n",
      "39312/39312 [==============================] - 4s 114us/step - loss: 0.3394 - acc: 0.8481\n",
      "Epoch 130/150\n",
      "39312/39312 [==============================] - 5s 128us/step - loss: 0.3378 - acc: 0.8481\n",
      "Epoch 131/150\n",
      "39312/39312 [==============================] - 5s 116us/step - loss: 0.3380 - acc: 0.8473\n",
      "Epoch 132/150\n",
      "39312/39312 [==============================] - 4s 113us/step - loss: 0.3376 - acc: 0.8494\n",
      "Epoch 133/150\n",
      "39312/39312 [==============================] - 5s 127us/step - loss: 0.3373 - acc: 0.8479\n",
      "Epoch 134/150\n",
      "39312/39312 [==============================] - 5s 133us/step - loss: 0.3372 - acc: 0.8468\n",
      "Epoch 135/150\n",
      "39312/39312 [==============================] - 5s 132us/step - loss: 0.3371 - acc: 0.8493\n",
      "Epoch 136/150\n",
      "39312/39312 [==============================] - 5s 118us/step - loss: 0.3366 - acc: 0.8496\n",
      "Epoch 137/150\n",
      "39312/39312 [==============================] - 5s 127us/step - loss: 0.3360 - acc: 0.8500\n",
      "Epoch 138/150\n",
      "39312/39312 [==============================] - 5s 136us/step - loss: 0.3357 - acc: 0.8484\n",
      "Epoch 139/150\n",
      "39312/39312 [==============================] - 5s 122us/step - loss: 0.3352 - acc: 0.8501\n",
      "Epoch 140/150\n",
      "39312/39312 [==============================] - 4s 111us/step - loss: 0.3356 - acc: 0.8491\n",
      "Epoch 141/150\n",
      "39312/39312 [==============================] - 4s 111us/step - loss: 0.3342 - acc: 0.8499\n",
      "Epoch 142/150\n",
      "39312/39312 [==============================] - 5s 125us/step - loss: 0.3359 - acc: 0.8493\n",
      "Epoch 143/150\n",
      "39312/39312 [==============================] - 5s 121us/step - loss: 0.3339 - acc: 0.8487\n",
      "Epoch 144/150\n",
      "39312/39312 [==============================] - 4s 112us/step - loss: 0.3350 - acc: 0.8491\n",
      "Epoch 145/150\n",
      "39312/39312 [==============================] - 4s 111us/step - loss: 0.3346 - acc: 0.8497\n",
      "Epoch 146/150\n",
      "39312/39312 [==============================] - 4s 110us/step - loss: 0.3336 - acc: 0.8484\n",
      "Epoch 147/150\n",
      "39312/39312 [==============================] - 4s 112us/step - loss: 0.3337 - acc: 0.8492\n",
      "Epoch 148/150\n",
      "39312/39312 [==============================] - 4s 113us/step - loss: 0.3331 - acc: 0.8497\n",
      "Epoch 149/150\n",
      "39312/39312 [==============================] - 4s 114us/step - loss: 0.3337 - acc: 0.8501\n",
      "Epoch 150/150\n",
      "39312/39312 [==============================] - 4s 110us/step - loss: 0.3326 - acc: 0.8503\n",
      "39312/39312 [==============================] - 1s 15us/step\n",
      "\n",
      "acc: 85.93%\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(data_, labels, epochs=15, batch_size=10)\n",
    "scores = model.evaluate(data_, labels)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
